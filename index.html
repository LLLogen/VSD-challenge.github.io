<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description" content="Visual Spatial Description Question Answerin.">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>ACM MM 2024 Grand Challenge: Visual Spatial Description</title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-PYVRSFMDRL');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <!--  <script src="./static/js/index.js"></script>-->
    <style>
        pre {outline: 1px solid #ccc; }
         .string { color: green; }
         .number { color: darkorange; }
         .boolean { color: blue; }
         .null { color: magenta; }
         .key { color: red; }
        ._table{width: 100%; border-collapse: collapse; border:0px;}
        ._table thead tr {font-size: 13px; color: #2e3b45;  text-align: center; background-color: rgba(230, 255, 250, 0.92); font-weight:bold;}
        ._table td{line-height: 20px; text-align: center; padding: 4px 10px 3px 10px; height: 18px;border: 0px solid #ffffff;}
        ._table tbody tr {background: #fff; font-size: 13px; color: #393939;}
        ._table tbody tr:nth-child(2n){ background: #f3f3f3;}
    </style>
</head>

<body>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">ACM MM 2024 Grand Challenge: Visual Spatial Description</h1>
<!--                         <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <!-- <span>Yu Zhao</span><sup>1</sup>,</span>
                                <a href="https://scholar.google.com/citations?user=jeW8EcYAAAAJ&hl=en">Yu Zhao</a><sup>1</sup></span>
                            <span class="author-block">
                                <a href="https://scofield7419.github.io">Hao Fei</a><sup>2</sup></span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup>Tianjin University</span>
                            <span class="author-block"><sup>2</sup>National University of Singapore</span>

                        </div> -->

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- Data Link. -->
                                <span class="link-block">
                                    <a href="#introduction"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span>Introduction</span>
                                    </a>
                                </span>
                                <!-- Data Link. -->
                                <span class="link-block">
                                    <a href="#dataset"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span>Dataset</span>
                                    </a>
                                </span>
                                <!-- Paper Link. -->
                                <span class="link-block">
                                    <a href="#task"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span>Task</span>
                                    </a>
                                </span>
                                <!-- Code Link. -->
                                <span class="link-block">
                                    <a href="#submission"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span>Submission</span>
                                    </a>
                                </span>
                                <!-- Demo Link. -->
<!--                                 <span class="link-block">
                                    <a href="#baseline"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span>Baseline</span>
                                    </a>
                                </span> -->
                                <!-- Participate Link. -->
                                <span class="link-block">
                                    <a href="https://docs.google.com/forms/d/e/1FAIpQLSfuKXhaN5qa61rWlwaE3VpJD5FHcVLH25Un95wch6fCKiXIGQ/viewform?usp=sf_link"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span>Participate</span>
                                    </a>
                                </span>
                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

<!--     <section class="hero teaser">
        <div class="container is-max-desktop" style="max-width: 55%!important;">
            <div class="hero-body">
                <div style="text-align: center;">
                    <img src="static/images/figure1.png" width="90%" alt="">
                </div>
                <h2 class="subtitle has-text-centered" style="text-align: left!important;">
                    Example in our dataset with the object pairs and their corresponding image and text that can describe the 
                    spatial relationships.
                </h2>
            </div>
        </div>
    </section> -->

    <section class="section"style="margin-top: -50px;">
        <div class="container is-max-desktop">

            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Leaderboard</h2>
                    <div class="content has-text-justified">
                        <p>
                            Congratulations to the winners!
                        </p>
                        <table class="._table table-bordered table-striped" align="center">
                            <tbody align="center" valign="center">
                            <tr>
                                <td>Rank</td>
                                <td>Team</td>
                                <td>Score</td>
                              </tr>
                            <tr>
                              <td>1</td>
                              <td>Token</td>
                              <td>63.2064</td>
                            </tr>
                            <tr>
                              <td>2</td>
                              <td>USTC-IAT-United</td>
                              <td>62.1149</td>
                            </tr>
                            <tr>
                                <td>3</td>
                                <td>ppjj</td>
                                <td>59.8638</td>
                            </tr>
                            <tr>
                                <td>4</td>
                                <td>GXU-LIPE</td>
                                <td>59.6864</td>
                            </tr>
                            <tr>
                                <td>5</td>
                                <td>DMCV</td>
                                <td>59.3998</td>
                            </tr>
                            
                        </tbody>
                        </table>
                    </div>
                </div>
            </div>
            
            <!-- Abstract. -->
            <div id="introduction" class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Introduction</h2>
                    <div class="content has-text-justified">
                        <p>
                            We propose the visual spatial description (VSD) challenge on the platform of ACM MM. This challenge falls within the research domain of visual spatial semantics understanding. In the VSD challenge, models and systems are expected to generate an accurate textual descriptive sentence to describe the spatial relationship between two given target objects in an input image. Alongside the challenge, a large-scale Visual Spatial Description dataset will be provided, consisting of 29,272 high-quality manually annotated image-text pairs. 
                        </p>
                        <p>
                            The challenge contains three subtasks, from easy to hard.
                        </p>
                    </div>
                </div>
            </div>
            <!--/ Abstract. -->

            <!-- Paper video. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Challenge Task Definition and Metrtics</h2>
                    <div class="content has-text-justified">
                        <div style="text-align: center;">
                            <img src="static/images/mmgc2024_task1.png" width="90%" alt="">
                            <p><b>Task 1: Classification of Visual Spatial Relationship.</b></p>
                        </div>
                        <p>
                            <b>Task-1:</b> Classification of Visual Spatial Relationship. Participants are required to construct models that can extract spatial relationships between two given objects O&#8321 and O&#8322 and output a triplet containing the spatial relationships of them. The relationships could be chosen from nine labels: “on”, “in”, “next”, “under”, “above”, “behind”, “in front of”, “left”, and “right”. The evaluation of this sub-task is the F1 score of the multi-label classification.
                        </p>
                         <p style="text-align: center;">
                                 <b><em>z<sub>1</sub> = F1</em></b>
                        <p>
                        <div style="text-align: center;">
                            <img src="static/images/mmgc2024_task2.png" width="90%" alt="">
                            <p><b>Task 2: Description of Single Spatial Relationship.</b></p>
                        </div>
                        <p>
                            <b>Task-2:</b> Description of Single Spatial Relationship.
                            Participants are required to build models that generate a textual description of the single spatial relationship between the two objects O&#8321 and O&#8322.
                            There are one or more ground-truth for each data entry.
                            We calculate BLEU-4 and SPICE for the predicted sentence and each ground truth and choose the max score.
                            We rank the submitted models by a weighted sum z of BLEU-4 and SPICE score:
                         <p>
                        <p style="text-align: center;">
                                 <b><em>z<sub>2</sub> = 0.4BLEU4 + 0.6SPICE</em></b>
                        </p>
                        <div style="text-align: center;">
                            <img src="static/images/mmgc2024_task3.png" width="90%" alt="">
                            <p><b>Task 3:  Description of open-ended spatial relationship.</b></p>
                        </div>
                        <p>
                            <b>Task-3:</b> Description of open-ended spatial relationship.
                            In this task, we provide a more challenging dataset that contains more complex spatial description.
                            Contestants are required to construct models that can generate textual description to describe the spatial relationship between O&#8321 and O&#8322. Different to task-2, in the task-3, the model should generate 3 diverse descriptions.
                            The evaluation of task-3 contains two parts, the Correctness and the Diversity.
                            For the correctness we use the SPICE as task-2.
                            For the diversity, we use mBLEU-4.
                        </p>
                        <p style="text-align: center;">
                                 <b><em>z<sub>3</sub> = 0.5*(50 - mBLEU4) + 0.5SPICE</em></b>
                        <p>
                        <p>
                           Finally, we use the following score for ranking:
                        </p>
                        <p>
                                 <b>overall=<em>0.2z<sub>1</sub>+0.3z<sub>2</sub>+0.5z<sub>3</sub></em></b>
                        <p>
                            We provide python scripts for evaluation, please refer to the <a href="#baseline">baseline codes</a>.
                    </div>
                </div>
            </div>
             <!-- Datasets. -->
            <div class="columns is-centered has-text-centered">
                <div id="dataset" class="column is-four-fifths">
                    <h2 class="title is-3">Dataset</h2>
                    <div class="content has-text-justified">
                        <p>
                             Our dataset comprises of two versions, VSDv1 and VSDv2, containing same images, two objects with bounding boxes, and spatial descriptions in English. The v2 contains more complicate sentences than v1.
                        </p>
                        <p>
                            Example of a sample:
                        </p>
                        <pre id="jsonShow">[
{
  "img_id": "1.jpg", // image id
  "triple_list": [
    {
      "s": "book",                          // tag of the subject 
      "o": "table",                         // tag of the object
      "p": "on",                            // predicate label, one of “on”, “in”, “next”, “under”, “above”, “behind”, “in front of”, “left”, and “right”
      "s_bbox": [ymin,ymax,xmin,xmax],      // coordinates of the subject box, with the 0 points at upper-left corner of the image. (xmin, ymin) is the upper-left corner of the box.
      "o_bbox": ymin,ymax,xmin,xmax],            // coordinates of the object box
    }
  ],
  "description": "The book is on the table."
}
]</pre>
                        <p>
                            The datasets (with images) are avaliable on <a href="https://drive.google.com/drive/folders/1PkkokJvGDPTUNiQKhE0TTxh_AvxRKNqt?usp=drive_link">Google Drive</a>
                        </p>
                    </div>
                </div>
            </div>
            
            <!-- / Paper video. -->
            <div class="columns is-centered has-text-centered">
                <div id="submission" class="column is-four-fifths">
                    <h2 class="title is-3">Submission</h2>
                    <div class="content has-text-justified">
                        <p>
                             Please sumbit predicted results with <b>TWO</b> json files, one for task1 and task2 (<b>task1-2.json</b>), the other for the task3 (<b>task3.json</b>).
                        </p>
                        <p>
                            For task1-2.json:
                        </p>
                        <pre id="jsonShow">[
{
    "img_id": "1.jpg", // image id
    "triple_list": [
    {
        "s": "book",                          // tag of the subject 
        "o": "table",                         // tag of the object
        <span style="color: #ff0000;">"p": "predicted label"</span>,                            // predicate label, one of “on”, “in”, “next”, “under”, “above”, “behind”, “in front of”, “left”, and “right”
        "s_bbox": [ymin,ymax,xmin,xmax],      // coordinates of the subject box, with the 0 points at upper-left corner of the image. (xmin, ymin) is the upper-left corner of the box.
        "o_bbox": ymin,ymax,xmin,xmax],       // coordinates of the object box
    }
    ],
    <span style="color: #ff0000;">"description": ["sentence1"]</span> // generated sentences
}
]</pre>
                        <p>
                            For task3.json:
                        </p>
                        <pre id="jsonShow">[
{
    "img_id": "1.jpg", // image id
    <span style="color: #ff0000;">"description": ["sentence1", "sentence2", "sentence3"]</span> // generated sentences
}
]</pre>
<!--                         <p>
                            Link to <a href="#">Codalab</a>
                        </p> -->
                        <p>
                            
                            Participants can submit at <a href="https://www.codabench.org/competitions/3125/">Codabench</a>, or send the results at in a Zip file to <a href="mailto: vsdchallenge@gmail.com">vsdchallenge@gmail.com</a>.
                            We will review the submissions publish the ranking here.
                        </p>
                    </div>
                </div>
            </div>

            <!-- / Paper video. -->
            <div class="columns is-centered has-text-centered">
                <div id="baseline" class="column is-four-fifths">
                    <h2 class="title is-3">Baseline</h2>
                    <div class="content has-text-justified">
                        <p>
                             We use pre-trained Vison-Language Models as the baselines.
                        </p>
                        <p>
                            Link to the code <a href="https://github.com/LLLogen/VSDcode">https://github.com/LLLogen/VSDcode</a>
                        </p>
                    </div>
                </div>
            </div>
            
            <!-- / Paper video. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Registration</h2>
                    <div class="content has-text-justified">
                        <p>
                             Welcome and please apply for the VSD challenge via a form at <a href="https://docs.google.com/forms/d/e/1FAIpQLSfuKXhaN5qa61rWlwaE3VpJD5FHcVLH25Un95wch6fCKiXIGQ/viewform?usp=sf_link">this link</a>.
                        </p>
                        <p>
                            Feel free to contact us at <a href="mailto: vsdchallenge@gmail.com">vsdchallenge@gmail.com</a>.
                        </p>
                    </div>
                </div>
            </div>

            <!-- / Paper video. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Timeline</h2>
                    <div class="content has-text-justified">
                        <p>
                            Please note: The submission deadline is at 11:59 p.m. (<a herf="https://www.timeanddate.com/time/zones/aoe" style="color:red">Anywhere on Earth</a>) of the stated deadline date.
                        </p>
                        <table class="._table table-bordered table-striped" align="center">
                            <tbody align="center" valign="center">
                            <tr>
                              <td>Registration open</td>
                              <td>May 24, 2024</td>
                            </tr>
                            <tr>
                              <td>Release of all datasets</td>
                              <td>MAy 28, 2024</td>
                            </tr>
                            <tr>
                                <td>Evaluation results and ranking open</td>
                                <td>June 10, 2024</td>
                            </tr>
                            <tr>
                                <td><del>System reports and conference paper deadline</del></td>
                                <td><del>July 12, 2024</del></td>
                            </tr>
                            <tr>
                                <td><b style="color: red">Results Submission Deadline</b></td>
                                <td><b style="color: red">August 1, 2024<b style="color: red"></td>
                            </tr>
                            <tr>
                                <td><b style="color: red">Challenge Paper Submission Deadline</b>(follow <a href="https://2024.acmmm.org/important-dates">MM2024 Workshop Dates</a>)</td>
                                <td><b style="color: red">August 19, 2024</b></td>
                            </tr>

                        </tbody>
                        </table>
                    </div>
                </div>
            </div>
            
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Rewards</h2>
                    <div class="content has-text-justified">
                        <p>
                            Top-ranked participants in this competition will receive a certificate of achievement and will be recommended to write a technical paper for submission to the <a>ACM ToMM Special Issue</a>.
                        </p>
                    </div>
                </div>
            </div>

            <!-- / Paper video. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Organizers</h2>
                    <div class="content has-text-justified">
                        <p>
                            <a href="https://scholar.google.com/citations?user=jeW8EcYAAAAJ&hl=en">Yu Zhao</a>. College of Intelligence and Computin, Tianjin University, China.
                        </p>
                        <p>
                             <a href="https://scholar.google.com/citations?user=YGDX46AAAAAJ&hl=en">Hao Fei</a>. Skywork AI, National University of Songalpore, Singapore.
                        </p>
                        <p>
                            <a href="https://scholar.google.com/citations?user=90mnP8MAAAAJ&hl=en&oi=ao">Bobo Li</a>. School of Cyber Science and Engineering, Wuhan University, China.
                        </p>
                        <p>
                            <a href="https://scholar.google.com/citations?user=k-chMpIAAAAJ&hl=en&oi=ao">Meishan Zhang</a>. Harbin Institute of Technology (Shenzhen), Shenzhen, China.
                        </p>
                        <p>
                            <a href="https://scholar.google.com/citations?user=CncXH-YAAAAJ&hl=en">Min Zhang</a>. Harbin Institute of Technology (Shenzhen), Shenzhen, China.
                        </p>
                    </div>
                </div>
            </div>


            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">References</h2>
                    <div class="content has-text-justified">
                        <p>
                            [1] Zhao, Y., Wei, J., Lin, Z., Sun, Y., Zhang, M., & Zhang, M. (2022, December). Visual Spatial Description: Controlled Spatial-Oriented Image-to-Text Generation. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (pp. 1437-1449).
                        </p>
                        <p>
                            [2] Zhao, Y., Fei, H., Ji, W., Wei, J., Zhang, M., Zhang, M., & Chua, T. S. (2023, July). Generating Visual Spatial Description via Holistic 3D Scene Understanding. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (pp. 7960-7977).
                        </p>
                        <p>
                            [3] Yang, K., Russakovsky, O., & Deng, J. (2019). Spatialsense: An adversarially crowdsourced benchmark for spatial relation recognition. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 2051-2060).
                        </p>
                        <p>
                            [4] Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., ... & Liu, P. J. (2020). Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of machine learning research, 21(140), 1-67.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

<!--     <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            Borrowed from <a href="https://github.com/nerfies/nerfies.github.io">source code</a>
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer> -->

</body>
<script>
    // function jsonShowFn(json){
    //     if (!json.match("^\{(.+:.+,*){1,}\}$")) {
    //         return json           //判断是否是json数据，不是直接返回
    //     }

    //     if (typeof json != 'string') {
    //         json = JSON.stringify(json, undefined, 2);
    //     }
    //     json = json.replace(/&/g, '&amp;').replace(/</g, '&lt;').replace(/>/g, '&gt;');
    //     return json.replace(/("(\\u[a-zA-Z0-9]{4}|\\[^u]|[^\\"])*"(\s*:)?|\b(true|false|null)\b|-?\d+(?:\.\d*)?(?:[eE][+\-]?\d+)?)/g, function(match) {
    //         var cls = 'number';
    //         if (/^"/.test(match)) {
    //             if (/:$/.test(match)) {
    //                 cls = 'key';
    //             } else {
    //                 cls = 'string';
    //             }
    //         } else if (/true|false/.test(match)) {
    //             cls = 'boolean';
    //         } else if (/null/.test(match)) {
    //             cls = 'null';
    //         }
    //         return '<span class="' + cls + '">' + match + '</span>';
    //     });
    // }
    // $('#jsonShow').html(jsonShowFn('[{"imd_id":1,"triple_list":["s":"book","o":"table"]}]'));
</script>
</html>
